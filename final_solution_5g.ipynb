{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction:\n",
        "5G, the fifth generation of radio technology, has brought about new services, technologies, and networking paradigms, with the corresponding social benefits. However, there is growing concern over the energy consumption of these new network deployments. While 5G networks are estimated to be about 4x more energy-efficient than 4G networks, their energy consumption is approximately 3x larger due to the need for a larger number of cells to provide the same coverage at higher frequencies and the increased processing required for wider bandwidths and more antennas. It is worth noting that, on average, network operational expenditure (OPEX) already accounts for around 25 percent of the total operatorâ€™s cost, and 90 percent of it is spent on large energy bills. More than 70 percent of this energy is estimated to be consumed by the radio access network (RAN), particularly by the base stations (BSs), while data centres and fibre transport account for a smaller share.(https://zindi.africa/competitions/aiml-for-5g-energy-consumption-modelling)"
      ],
      "metadata": {
        "id": "gXwyaUAe2ObP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives:\n",
        "\n",
        "**Objective A: Estimating Energy Consumption in Specific Base Station Products:** For this objective, it's understood that specific base information, their configurations, and a historical usage, typically spanning a complete week, were received. In this scenario, the training data, and primarily the history of energy expenditure, were used to determine the best forecasting patterns. It was found that treating this as a time-series problem yielded the best results. The model uses energy and load along with the seasonality of each base's use to pinpoint the most accurate energy estimates.\n",
        "\n",
        "**Objective B: Generalization Across Different Base Station Products:** In this scenario, I understood that having a history of bases with similar configurations enables using that history to forecast a new base that uses similar configurations. Here, we face a different problem because the user usage history and its hourly seasonality become irrelevant, as does the energy history. It's still possible to treat it as a time-series problem by using lags and other such features. However, what showed the best result was the use of complex features concerning the new bases' configurations. This shows that there still exists a way to use historical data to forecast unknown futures and that they still have a certain strong correlation. The issue transforms into a hybrid problem, combining elements of time-series analysis and complex methods to identify patterns in new base configurations for precise energy prediction.\n",
        "\n",
        "**ObjC - Generalization across different base station configurations:** In this scenario, it's understood that besides new databases, the model should also generalize to new base configurations, often with significant differences, making it practically impossible to use other bases' history for forecasting energy consumption. After several optimizations and tests, it was understood that there wasn't a possibility to create a complex model and that the history of data did not hold much relevance. Characteristics such as load, EMS Modes 1, 2, and 6 gained importance. It was noticed that the simpler the model, the better it performed and the more general it became. Therefore, all robust features and all time-series features were removed, generating greater generalization power and avoiding overfitting."
      ],
      "metadata": {
        "id": "1JmVMuBf4AG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "jxMbX3R94nrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from xgboost import DMatrix, train\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "np.random.seed(42)\n",
        "import math\n",
        "import random"
      ],
      "metadata": {
        "id": "uU9LNU-k2PTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "6aqzkozl4xF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pcp_df = pd.read_csv(\"/kaggle/input/reseau5g/imgs_202307101549519358.csv\")\n",
        "cl_df = pd.read_csv(\"/kaggle/input/reseau5g/imgs_2023071012130978799.csv\")\n",
        "bs_df = pd.read_csv(\"/kaggle/input/reseau5g/imgs_2023071012123392536.csv\")\n",
        "ec_df  = pd.read_csv(\"/kaggle/input/reseau5g/imgs_2023071012133740345.csv\")\n",
        "ss_df = pd.read_csv(\"/kaggle/input/reseau5g/SampleSubmission (24).csv\")\n",
        "pcp_df.shape, cl_df.shape, bs_df.shape, ec_df.shape, ss_df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T20:06:57.338300Z",
          "iopub.execute_input": "2023-10-10T20:06:57.338882Z",
          "iopub.status.idle": "2023-10-10T20:06:57.542767Z",
          "shell.execute_reply.started": "2023-10-10T20:06:57.338848Z",
          "shell.execute_reply": "2023-10-10T20:06:57.541780Z"
        },
        "trusted": true,
        "id": "lFgfAjbE2K0e",
        "outputId": "90e0296a-decd-47a6-8095-31cac8fbc2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((26139, 4), (125575, 10), (1217, 8), (92629, 3), (26139, 2))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_bs_df = cl_df.merge(bs_df, on=['BS', 'CellName'], how='left')\n",
        "cl_bs_df = cl_bs_df.pivot(\n",
        "    index=['Time','BS'],columns=['CellName'],\n",
        "    values=['CellName']\n",
        ").reset_index()\n",
        "cl_bs_df.columns = ['_'.join([str(i) for i in x]) for x in cl_bs_df.columns]\n",
        "cl_bs_df.columns = cl_bs_df.columns.str.strip('_')\n",
        "df= cl_bs_df.merge(bs_df.groupby('BS')[['RUType','Mode','Frequency','Antennas','Bandwidth']].first().reset_index(), on='BS', how='left')\n",
        "df= df.merge(cl_df.groupby(['BS','Time'])[['load','ESMode1','ESMode2','ESMode3','ESMode4','ESMode5','ESMode6']].sum().reset_index(), on=['BS',\"Time\"], how='left')\n",
        "df= df.merge(bs_df.groupby('BS')[['TXpower']].max().reset_index(), on='BS', how='left')\n",
        "df=df.fillna(0)\n",
        "df['CellName_Cell1'].replace({'Cell1': 1}, inplace=True)\n",
        "df['CellName_Cell2'].replace({'Cell2': 1}, inplace=True)\n",
        "df = df.merge(ec_df, on=['Time', 'BS'], how='left')"
      ],
      "metadata": {
        "id": "mqFhd7Vu2K0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "sns.lineplot(data=df, x='Time', y='Energy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J80oc0co2K0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(df, x='RUType', y=\"Energy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GYt2KzZO2K0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "sns.lineplot(data=df, x='Time', y='Energy', hue='Mode')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G_WfH7Ux2K0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engeniring"
      ],
      "metadata": {
        "id": "-TlJG8145DM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Feature_Engineering(df):\n",
        "    df['Time'] = pd.to_datetime(df['Time'])\n",
        "    df['Hour'] = df['Time'].dt.hour\n",
        "    df['Day'] = df['Time'].dt.day\n",
        "    df['Dayofweek'] = df['Time'].dt.dayofweek\n",
        "    df[\"periode\"]=None\n",
        "    for i in range(118768):\n",
        "        if 0 <= df.loc[i, 'Hour'] <= 5:\n",
        "            df.loc[i, 'periode'] = 0\n",
        "        elif 6 <= df.loc[i, 'Hour'] < 10:\n",
        "            df.loc[i, 'periode'] = 1\n",
        "        elif 11 <= df.loc[i, 'Hour'] < 20:\n",
        "            df.loc[i, 'periode'] = 2\n",
        "        else:\n",
        "            df.loc[i, 'periode'] = 3\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['ID'] = df['Time'].astype('str') + '_' + df['BS']\n",
        "    df['BS'] = df['BS'].apply(lambda x: int(x.strip('B_')))\n",
        "    df['periode'] = label_encoder.fit_transform(df['periode'])\n",
        "    df['RUType'] = label_encoder.fit_transform(df['RUType'])\n",
        "    df['Mode'] = label_encoder.fit_transform(df['Mode'])\n",
        "    df = pd.get_dummies(df, columns=['RUType','Day','Hour','Mode'],drop_first=True,dtype=float)\n",
        "    df=df.sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)\n",
        "    BS_mean = df.groupby('BS')['load'].mean().to_dict()\n",
        "    BS_std = df.groupby('BS')['load'].std().to_dict()\n",
        "    BS_median = df.groupby('BS')['load'].median().to_dict()\n",
        "    df['totbo51'] = df['BS'].map(BS_mean)\n",
        "    df['totbo52'] = df['BS'].map(BS_std)\n",
        "    df['totbo53'] = df['BS'].map(BS_median)\n",
        "    df['previous'] = df.groupby('BS')[['Energy']].shift(1)\n",
        "    df['previousload'] = df.groupby('BS')[['load']].shift(1)\n",
        "    df['previous'] = df.groupby('BS')['previous'].fillna(method='ffill')\n",
        "    df['previous'] = df.groupby('BS')['previous'].fillna(method='bfill')\n",
        "    df['previousl'] = df.groupby('BS')['previousl'].fillna(method='bfill')\n",
        "Feature_Engineering(df)"
      ],
      "metadata": {
        "id": "8pfkdwXq2K0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "3x5ms_105Ijy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train1= df[~df['Energy'].isna()]\n",
        "test = df[df['Energy'].isna()]\n",
        "train1=train1[train1['BS']!=838]\n",
        "train1=train1[train1['BS']!=859]\n",
        "train1=train1[train1['BS']!=835]\n",
        "train1=train1[train1['BS']!=854]\n",
        "train1 = train1.sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)\n",
        "test = test.sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)\n",
        "x=train1.drop(columns=['Energy',\"ID\",\"Time\",'ESMode4','ESMode5','Frequency','CellName_Cell0','CellName_Cell3'])\n",
        "y=train1['Energy']\n",
        "test1=test.drop(columns=['Energy','Time',\"ID\",'ESMode4','ESMode5','Frequency','CellName_Cell0','CellName_Cell3'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T20:06:57.555506Z",
          "iopub.execute_input": "2023-10-10T20:06:57.556095Z",
          "iopub.status.idle": "2023-10-10T20:24:58.541014Z",
          "shell.execute_reply.started": "2023-10-10T20:06:57.556064Z",
          "shell.execute_reply": "2023-10-10T20:24:58.539854Z"
        },
        "trusted": true,
        "id": "HhX-ftD62K0g",
        "outputId": "652ccdd7-68d2-4093-dff8-aa4636b28102"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_115/3590102955.py:19: RuntimeWarning: invalid value encountered in double_scalars\n  step = (next_value - current_value) / (end_idx - start_idx + 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.DataFrame(train1['BS'].value_counts().reset_index())\n",
        "datatest = pd.DataFrame(test['BS'].value_counts().reset_index().reset_index(drop=True))\n",
        "l = list(data1['BS'].values)\n",
        "mask = datatest[\"BS\"].isin(l)\n",
        "filtered_datatest = datatest[~mask]\n",
        "filtered_datatest1 = datatest[mask]\n",
        "l1=list(filtered_datatest['BS'])\n",
        "l2=list(filtered_datatest1['BS'])\n",
        "test_indexNBS=[]\n",
        "for v in l2:\n",
        "      test_indexNBS.append(test[test['BS']==v].index)\n",
        "test_indexNBS = [item for sublist in test_indexNBS for item in sublist]\n",
        "testNBS=test1.iloc[test_indexNBS]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T20:44:45.651325Z",
          "iopub.execute_input": "2023-10-10T20:44:45.651998Z",
          "iopub.status.idle": "2023-10-10T20:44:45.679137Z",
          "shell.execute_reply.started": "2023-10-10T20:44:45.651963Z",
          "shell.execute_reply": "2023-10-10T20:44:45.678005Z"
        },
        "trusted": true,
        "id": "NvH8AZsO2K0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Post_processing(datatest,data):\n",
        "    lmin = pd.DataFrame(data.groupby('BS')[['Energy']].min()).reset_index()\n",
        "    lmax = pd.DataFrame(data.groupby('BS')[['Energy']].max()).reset_index()\n",
        "    l=np.unique(data['BS'])\n",
        "    for i in range(23188):\n",
        "        bs = datatest['BS'][i]\n",
        "        if bs in l:\n",
        "            if datatest['Energy'][i] > lmax['Energy'].loc[lmax['BS'] == bs].values[0]:\n",
        "                datatest['Energy'][i] = lmax['Energy'].loc[lmax['BS'] == bs].values[0]\n",
        "            elif datatest['Energy'][i] < lmin['Energy'].loc[lmin['BS'] == bs].values[0]:\n",
        "                datatest['Energy'][i] = lmin['Energy'].loc[lmin['BS'] == bs].values[0]\n",
        "    return datatest"
      ],
      "metadata": {
        "id": "6LISuU-F5bp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "UKZj6hfl5Qre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds1CatBoost = []\n",
        "def creat_model_catboost():\n",
        "    params = {\n",
        "        'loss_function': 'MAE',\n",
        "        'iterations': 100000,\n",
        "        'early_stopping_rounds': 500,\n",
        "        'verbose': 1000,\n",
        "        'l2_leaf_reg': 5,\n",
        "        'max_depth': 8,\"random_state\":42,'task_type': 'GPU' }\n",
        "    num_folds = 10\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "    for fold_num, (train_index, test_index) in enumerate(kf.split(x)):\n",
        "        X_train, X_val = x.iloc[train_index], x.iloc[test_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
        "        dtrain = Pool(X_train, label=y_train)\n",
        "        dval = Pool(X_val, label=y_val)\n",
        "        dtest = Pool(testNBS)\n",
        "        rf_regressor1 = CatBoostRegressor(**params)\n",
        "        rf_regressor1.fit(dtrain, eval_set=dval)\n",
        "        best_iteration = rf_regressor1.get_best_iteration()\n",
        "        y_pred = rf_regressor1.predict(dval)\n",
        "        feature_importance = rf_regressor1.get_feature_importance()\n",
        "        feature_names = rf_regressor1.feature_names_\n",
        "        sorted_idx = feature_importance.argsort()[::-1]\n",
        "        top_n = 25\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(range(top_n), feature_importance[sorted_idx][:top_n], align='center')\n",
        "        plt.xticks(range(top_n), [feature_names[i] for i in sorted_idx][:top_n], rotation=90)\n",
        "        plt.xlabel('Feature')\n",
        "        plt.ylabel('Feature Importance')\n",
        "        plt.title('Top 20 Feature Importances')\n",
        "        plt.show()\n",
        "        mae = mean_absolute_error(y_val, y_pred)\n",
        "        print(f\"Fold {fold_num + 1} MAE: {mae:.2f}\")\n",
        "        y_pred_test = rf_regressor1.predict(dtest)\n",
        "        preds1CatBoost.append(y_pred_test)\n",
        "    return preds1CatBoost,rf_regressor1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-10T20:44:32.685685Z",
          "iopub.execute_input": "2023-10-10T20:44:32.686796Z",
          "iopub.status.idle": "2023-10-10T20:44:33.787241Z",
          "shell.execute_reply.started": "2023-10-10T20:44:32.686742Z",
          "shell.execute_reply": "2023-10-10T20:44:33.785992Z"
        },
        "trusted": true,
        "id": "2ghhqi5d2K0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creat_model_xgboost():\n",
        "    preds1xgb=[]\n",
        "    scoore=[]\n",
        "    num_folds = 10\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "    for fold_num, (train_index, test_index) in enumerate(kf.split(x)):\n",
        "        X_train, X_val = x.iloc[train_index], x.iloc[test_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
        "        dtrain = DMatrix(X_train, label=y_train)\n",
        "        dval = DMatrix(X_val, label=y_val)\n",
        "        dtest=DMatrix(testNBS)\n",
        "        params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'mae','lambda': 5,\n",
        "          'max_depth': 5,'random_state':42\n",
        "        }\n",
        "        bst = train(\n",
        "        params,\n",
        "        dtrain,num_boost_round=20000,\n",
        "        early_stopping_rounds=200,\n",
        "        verbose_eval=500,\n",
        "        evals=[(dtrain, 'train'), (dval, 'val')]\n",
        "        )\n",
        "        plt.figure(figsize=(30, 30))\n",
        "        xgb.plot_importance(bst,max_num_features=25)\n",
        "        plt.show()\n",
        "        best_iteration = bst.best_iteration\n",
        "        scoore.append(bst.best_score)\n",
        "        y_predtest = bst.predict(dtest,iteration_range=(0, best_iteration))\n",
        "        preds1xgb.append(y_predtest)\n",
        "    print(np.mean(scoore, axis=0))\n",
        "    return preds1xgb,bst"
      ],
      "metadata": {
        "trusted": true,
        "id": "9GC1ZvKT2K0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds1CatBoost,rf_regressor1=creat_model()\n",
        "tesCatBoosttNSS1=test.iloc[test_indexNBS]\n",
        "y_predCatBoostNBS = np.mean(preds1CatBoost, axis=0)\n",
        "tesCatBoosttNSS1['Energy']=y_predCatBoostNBS\n",
        "tesCatBoosttNSS1=tesCatBoosttNSS1.reset_index(drop=True)\n",
        "tesCatBoosttNSS1=Post_processing(tesCatBoosttNSS1,train1)\n",
        "mergedCatBoost = pd.concat([train1, tesCatBoosttNSS1], axis= 0).sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T19:57:17.142664Z",
          "iopub.execute_input": "2023-10-09T19:57:17.143060Z",
          "iopub.status.idle": "2023-10-09T19:57:17.243477Z",
          "shell.execute_reply.started": "2023-10-09T19:57:17.143028Z",
          "shell.execute_reply": "2023-10-09T19:57:17.242686Z"
        },
        "trusted": true,
        "id": "0gHRha_o2K0h",
        "outputId": "2c50faf8-613d-4a7f-87cc-a8588b2c3e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_33/1391404788.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  tesCatBoosttNSS1['Energy']=y_predCatBoostNBS\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1xgb,bst=creat_model_xgboost()\n",
        "testxgbNSS1=test.iloc[test_indexNBS]\n",
        "y_predxgbNBS = np.mean(preds1xgb, axis=0)\n",
        "testxgbNSS1['Energy']=y_predxgbNBS\n",
        "testxgbNSS1=testxgbNSS1.reset_index(drop=True)\n",
        "testxgbNSS1=Post_processing(testxgbNSS1,train1)\n",
        "mergedxgb = pd.concat([train1, testxgbNSS1], axis= 0).sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bp20HjI62K0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unknown_BS(df,dftest):\n",
        "    train1= df[~df['Energy'].isna()]\n",
        "    x1CatBoost=train1.drop(columns=['totbo51','totbo52','totbo53','previous','rolling_mean','Rolling_Std','Energy',\"ID\",\"Time\",'BS','ESMode4','ESMode5','Frequency','CellName_Cell0','CellName_Cell3'])\n",
        "    yCatBoost=train1['Energy']\n",
        "    test2=dftest.drop(columns=['totbo51','totbo52','totbo53','previous','rolling_mean','Rolling_Std','Energy','Time',\"ID\",'BS','ESMode4','ESMode5','Frequency','CellName_Cell0','CellName_Cell3'])\n",
        "    test_indexBS=[]\n",
        "    for v in l1:\n",
        "          test_indexBS.append(dftest[dftest['BS']==v].index)\n",
        "    test_indexBS = [item for sublist in test_indexBS for item in sublist]\n",
        "    testBS=test2.iloc[test_indexBS]\n",
        "    testBSS=test.iloc[test_indexBS]\n",
        "    return testBS,testBSS\n",
        "testBSCatBoost,testBSSCatBoost=unknown_BS(mergedCatBoost,test)\n",
        "testBSxgb,testBSSxgb=unknown_BS(mergedxgb,test)"
      ],
      "metadata": {
        "id": "WncjPuau2K0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_grouping(values, ind,target_sum):\n",
        "    groups = [[]]\n",
        "    index = [[]]\n",
        "    for i in range(len(values)):\n",
        "        added = False\n",
        "        for j in range(len(groups)):\n",
        "            if sum(groups[j]) + values[i] <= target_sum:\n",
        "                groups[j].append(values[i])\n",
        "                index[j].append(ind[i])\n",
        "                added = True\n",
        "                break\n",
        "        if not added:\n",
        "            groups.append([values[i]])\n",
        "            index.append([ind[i]])\n",
        "    return index,groups\n",
        "random.seed(42)\n",
        "data=pd.DataFrame(train1['BS'].value_counts().reset_index())\n",
        "data = data.sample(frac=1, random_state=42)\n",
        "values = list(data['count'])\n",
        "ind=list(data['BS'])\n",
        "target_sum = 12000\n",
        "index,result = greedy_grouping(values,ind ,target_sum)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T19:59:26.904381Z",
          "iopub.execute_input": "2023-10-09T19:59:26.904769Z",
          "iopub.status.idle": "2023-10-09T19:59:26.923643Z",
          "shell.execute_reply.started": "2023-10-09T19:59:26.904722Z",
          "shell.execute_reply": "2023-10-09T19:59:26.922807Z"
        },
        "trusted": true,
        "id": "ZKuSH7r92K0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creat_model_catboost_unknown_BS()\n",
        "    preds2catboost = []\n",
        "    params = {\n",
        "        'loss_function': 'MAE',\n",
        "        'iterations': 100000,\n",
        "        'early_stopping_rounds': 500,\n",
        "        'verbose': 1000,\n",
        "        'l2_leaf_reg': 5,\n",
        "        'max_depth': 5#jarib 5\n",
        "\n",
        "    }\n",
        "\n",
        "    num_folds = 10\n",
        "    for fold_num in range(10):\n",
        "        test_index=[]\n",
        "        train_index=[]\n",
        "        for v in index[fold_num]:\n",
        "          test_index.append(train1[train1['BS']==v].index)\n",
        "        test_index = [item for sublist in test_index for item in sublist]\n",
        "        index1=index.copy()\n",
        "        l=index1.pop(fold_num)\n",
        "        index1 = [item for sublist in index1 for item in sublist]\n",
        "        for v in index1:\n",
        "          train_index.append(train1[train1['BS']==v].index)\n",
        "        train_index = [item for sublist in train_index for item in sublist]\n",
        "        print(len(train_index),len(test_index))\n",
        "        X_train, X_val = x1CatBoost.iloc[train_index], x1CatBoost.iloc[test_index]\n",
        "        y_train, y_val = yCatBoost.iloc[train_index], yCatBoost.iloc[test_index]\n",
        "        dtrain = Pool(X_train, label=y_train)\n",
        "        dval = Pool(X_val, label=y_val)\n",
        "        dtest = Pool(testBSCatBoost)\n",
        "        rf_regressor1 = CatBoostRegressor(**params)\n",
        "        rf_regressor1.fit(dtrain, eval_set=dval)\n",
        "        best_iteration = rf_regressor1.get_best_iteration()\n",
        "        y_pred = rf_regressor1.predict(dval)\n",
        "        feature_importance = rf_regressor1.get_feature_importance()\n",
        "        feature_names = rf_regressor1.feature_names_\n",
        "        sorted_idx = feature_importance.argsort()[::-1]\n",
        "        top_n = 25\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(range(top_n), feature_importance[sorted_idx][:top_n], align='center')\n",
        "        plt.xticks(range(top_n), [feature_names[i] for i in sorted_idx][:top_n], rotation=90)\n",
        "        plt.xlabel('Feature')\n",
        "        plt.ylabel('Feature Importance')\n",
        "        plt.title('Top 25 Feature Importances')\n",
        "        plt.show()\n",
        "        mae = mean_absolute_error(y_val, y_pred)\n",
        "        print(f\"Fold {fold_num + 1} MAE: {mae:.2f}\")\n",
        "        y_pred_test = rf_regressor1.predict(dtest)\n",
        "        preds2catboost.append(y_pred_test)\n",
        "        return preds2catboost,rf_regressor1\n",
        "preds2catboost,rf_regressor1=creat_model_catboost_unknown_BS()"
      ],
      "metadata": {
        "trusted": true,
        "id": "0UKbH-Gd2K0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creat_model_xgboost_unknown_BS()\n",
        "    preds2xgb=[]\n",
        "    num_folds = 10\n",
        "    for fold_num in range(10):\n",
        "        test_index=[]\n",
        "        train_index=[]\n",
        "        for v in index[fold_num]:\n",
        "          test_index.append(train1[train1['BS']==v].index)\n",
        "        test_index = [item for sublist in test_index for item in sublist]\n",
        "        index1=index.copy()\n",
        "        l=index1.pop(fold_num)\n",
        "        index1 = [item for sublist in index1 for item in sublist]\n",
        "        for v in index1:\n",
        "          train_index.append(train1[train1['BS']==v].index)\n",
        "        train_index = [item for sublist in train_index for item in sublist]\n",
        "        print(len(train_index),len(test_index))\n",
        "        X_train, X_val = x1xgb.iloc[train_index], x1xgb.iloc[test_index]\n",
        "        y_train, y_val = yxgb.iloc[train_index], yxgb.iloc[test_index]\n",
        "        dtrain = DMatrix(X_train, label=y_train)\n",
        "        dval = DMatrix(X_val, label=y_val)\n",
        "        dtest=DMatrix(testBSxgb)\n",
        "        params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'mae','lambda': 5,\n",
        "          'max_depth': 5\n",
        "        }\n",
        "\n",
        "        bst = train(\n",
        "        params,\n",
        "        dtrain,num_boost_round=10000,\n",
        "        early_stopping_rounds=500,\n",
        "        verbose_eval=500,\n",
        "        evals=[(dtrain, 'train'), (dval, 'val')]\n",
        "        )\n",
        "        plt.figure(figsize=(30, 30))\n",
        "        xgb.plot_importance(bst,max_num_features=25)\n",
        "        plt.show()\n",
        "        best_iteration = bst.best_iteration\n",
        "        scoore.append(bst.best_score)\n",
        "        y_predtest = bst.predict(dtest,iteration_range=(0, best_iteration))\n",
        "        preds2xgb.append(y_predtest)\n",
        "    print(np.mean(scoore, axis=0))\n",
        "    return preds2xgb,bst\n",
        "preds2xgb,bst=creat_model_xgboost_unknown_BS()"
      ],
      "metadata": {
        "trusted": true,
        "id": "vV85vrbP2K0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predCatBoostBS = np.mean(preds2catboost, axis=0)\n",
        "y_predxgbBS = np.mean(preds2xgb, axis=0)\n",
        "testBSSCatBoost['Energy']=y_predCatBoostBS\n",
        "testBSSxgb['Energy']=y_predxgbBS\n",
        "predcatboost = pd.concat([tesCatBoosttNSS1, testBSSCatBoost], axis= 0).sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)\n",
        "predxgb = pd.concat([testxgbNSS1, testBSSxgb], axis= 0).sort_values(by=['BS', 'Time'], ascending=[True, True]).reset_index(drop=True)\n",
        "pred=predcatboost['Energy']*0.65+predxgb['Energy']*0.35"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-08T23:12:13.743672Z",
          "iopub.execute_input": "2023-10-08T23:12:13.745019Z",
          "iopub.status.idle": "2023-10-08T23:12:13.776595Z",
          "shell.execute_reply.started": "2023-10-08T23:12:13.744969Z",
          "shell.execute_reply": "2023-10-08T23:12:13.775516Z"
        },
        "trusted": true,
        "id": "ICEJY45S2K0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "AN34llmo5qua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['Energy']=predcatboost['Energy']\n",
        "ss_df = ss_df[['ID']]\n",
        "ss_df = ss_df.merge(test[['ID', 'Energy']], on='ID', how='left')\n",
        "ss_df.to_csv(\"/kaggle/working/SampleSubmission (24).csv\",index=False)\n",
        "ss_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-09T20:13:24.460524Z",
          "iopub.execute_input": "2023-10-09T20:13:24.460908Z",
          "iopub.status.idle": "2023-10-09T20:13:24.582655Z",
          "shell.execute_reply.started": "2023-10-09T20:13:24.460878Z",
          "shell.execute_reply": "2023-10-09T20:13:24.581531Z"
        },
        "trusted": true,
        "id": "pPS_SEOg2K0i",
        "outputId": "b6ecffd0-c29f-428b-d546-fe0d25584c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 183,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                               ID     Energy\n0         2023-01-01 06:00:00_B_0  60.784380\n1         2023-01-01 11:00:00_B_0  73.263328\n2         2023-01-01 12:00:00_B_0  70.988538\n3         2023-01-01 13:00:00_B_0  73.492854\n4         2023-01-01 23:00:00_B_0  80.346904\n...                           ...        ...\n26134  2023-01-02 19:00:00_B_1019  20.079494\n26135  2023-01-02 20:00:00_B_1019  20.006799\n26136  2023-01-02 21:00:00_B_1019  20.041855\n26137  2023-01-02 22:00:00_B_1019  20.044033\n26138  2023-01-02 23:00:00_B_1019  19.852814\n\n[26139 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-01-01 06:00:00_B_0</td>\n      <td>60.784380</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-01-01 11:00:00_B_0</td>\n      <td>73.263328</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-01-01 12:00:00_B_0</td>\n      <td>70.988538</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-01-01 13:00:00_B_0</td>\n      <td>73.492854</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-01-01 23:00:00_B_0</td>\n      <td>80.346904</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26134</th>\n      <td>2023-01-02 19:00:00_B_1019</td>\n      <td>20.079494</td>\n    </tr>\n    <tr>\n      <th>26135</th>\n      <td>2023-01-02 20:00:00_B_1019</td>\n      <td>20.006799</td>\n    </tr>\n    <tr>\n      <th>26136</th>\n      <td>2023-01-02 21:00:00_B_1019</td>\n      <td>20.041855</td>\n    </tr>\n    <tr>\n      <th>26137</th>\n      <td>2023-01-02 22:00:00_B_1019</td>\n      <td>20.044033</td>\n    </tr>\n    <tr>\n      <th>26138</th>\n      <td>2023-01-02 23:00:00_B_1019</td>\n      <td>19.852814</td>\n    </tr>\n  </tbody>\n</table>\n<p>26139 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    }
  ]
}